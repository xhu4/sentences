{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentences - find similar sentences\n",
    "\n",
    "This is a homework project for Craig Douglas' [*Big Data and Mining*](http://mgnet.org/~douglas/Classes/bigdata/index.html) class, written in python. This is my second trial. My first trial is written in C and used a different definition of distance and is not *github*-ed.\n",
    "\n",
    "## Problem Description\n",
    "\n",
    "### Distance Function\n",
    "\n",
    "A *change* to a sentence $\\alpha$ can be:\n",
    "\n",
    "* deleting a word from $\\alpha$;\n",
    "* or adding a word to $\\alpha$.\n",
    "\n",
    "A distance function $d(\\cdot,\\cdot)$ of sentences is then defined as:\n",
    "\n",
    "$$ d(\\alpha,\\beta):=\\text{minimum number of changes applied to $\\alpha$ to get $\\beta$}\n",
    ". $$\n",
    "\n",
    "The goal is to filter out a set of sentences in a text file, given $k$, such that:\n",
    "\n",
    "* for any two distinct sentences $\\alpha, \\beta$ in output file, $d(\\alpha,\\beta)>k$,\n",
    "* and for every sentence $\\alpha$ in the input file, there is at least a sentence $\\beta$ in \n",
    "  the output file such that $d(\\alpha,\\beta)\\le k$.\n",
    "\n",
    "---\n",
    "\n",
    "## Usage\n",
    "\n",
    "This code is written in Python 2 but should be compatible with python3. 4 currently built-in \n",
    "modules are employed: `timeit`, `collections`, `itertools`, and `argparse`.\n",
    "\n",
    "Run `python[3] sentences.py -h` to show usage information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sentences.py [-h] [-d [K]] [-o [filename]] [infile]\n",
      "\n",
      "Solve Big Sentences Problem.\n",
      "\n",
      "positional arguments:\n",
      "  infile                input file\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -d [K], --dist [K]    Distance k, default: 0\n",
      "  -o [filename], --outfile [filename]\n",
      "                        Output filename. No output file will be generated if\n",
      "                        not provided.\n"
     ]
    }
   ],
   "source": [
    "!python sentences.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Solve distance 2 problem on *1M.txt*, and write the result to file *out.txt*:\n",
    "\n",
    "```sh\n",
    "python sentences.py 1M.txt -d2 -o out.txt\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Algorithm\n",
    "\n",
    "For distance 0, `set` container is used to remove identical sentences. The code without I/O \n",
    "can be implemented in one line:\n",
    "\n",
    "```python\n",
    "distinct_sentences = set(input_sentences)\n",
    "```\n",
    "\n",
    "Since `set` is implemented using hash table, this algorithm has a linear complexity to the \n",
    "number of sentences.\n",
    "\n",
    "The rest of this section talks about solving $k>1$.\n",
    "\n",
    "### Basic Idea\n",
    "\n",
    "We define some notations as follows:\n",
    "\n",
    "* $l(\\alpha)$: number of words of sentence $\\alpha$;\n",
    "* $\\alpha - n$: set of all strings that are sentence `\\alpha` delete $n$ words;\n",
    "* $\\alpha -m = \\beta - n$: $(\\alpha-m) \\cap (\\beta-n) \\ne \\emptyset$. Or, there exists a way \n",
    "  such that sentence $\\alpha$ removing some $m$ words is identical to sentence $\\beta$ \n",
    "  removing $n$ words;\n",
    "  \n",
    "Given two sentences $\\alpha$ and $beta$, if\n",
    "\n",
    "$$ \\alpha-m = \\beta-n, $$\n",
    "\n",
    "then\n",
    "\n",
    "$$ d(\\alpha, \\beta) = m+n-2p, \\text{ for some } p \\in \\mathbb{N}.$$\n",
    "\n",
    "If $l(\\alpha)-l(\\beta)=h\\ge0$, since $l(\\alpha)-m = l(\\beta)-n$, must have $m-n=h$. Thus\n",
    "\n",
    "$$ d(A,B) = h+2n+2p = h+2t, \\text{ for some } t\\in\\mathbb{N}. $$\n",
    "\n",
    "Then $d(\\alpha, \\beta) \\le k$ if and only if\n",
    "\n",
    "$$ \\alpha - (t+h) = \\beta - t, \\text{ and } 2t+h\\le k, $$\n",
    "which is equivalent as\n",
    "$$ \\alpha - (t+h) = \\beta - t,\\; t=\\operatorname{floor}\\left(\\frac{k-h}2\\right). $$\n",
    "\n",
    "### Functions\n",
    "\n",
    "For a set $A$ of $p$-word sentences, and a set $B$ of $q$-word sentences, say we want to \n",
    "remove all $\\beta\\in B$, where $d(\\alpha, \\beta)\\le k$ for some $\\alpha\\in A$. Without loss of \n",
    "generality, we assume $p\\ge q$. Two functions are written to solve two different cases: $p = q,\n",
    "\\; \\;0<p-q\\le k$, which are `amam()` and `ambn()` respectively.\n",
    "\n",
    "### Traps and Tricks\n",
    "\n",
    "One can easily end up deleting more sentences than they should when $k>0$. For example, we \n",
    "decide to remove $\\alpha$ because $d(\\alpha, \\beta)\\le k$ for some $\\beta$, and then remove \n",
    "$\\beta$ because $d(\\beta, \\gamma)\\le k$, then there is a chance we cannot find any sentence in \n",
    "our result within distance $k$ of $\\alpha$. To avoid such situation, we go through all \n",
    "sentences from the longest to the shortest, and always remove the shorter sentences when a \n",
    "pair of neighbors is found.\n",
    "\n",
    "---\n",
    "\n",
    "## Result & Performance\n",
    "\n",
    "File metadata:\n",
    "\n",
    "| Input file | # of lines | file size |\n",
    "| :--------: | ---------- | --------- |\n",
    "|  100.txt   | 100        | 12K       |\n",
    "|   1K.txt   | 1,000      | 96K       |\n",
    "|  10K.txt   | 10,000     | 884K      |\n",
    "|  100K.txt  | 100,000    | 8.4M      |\n",
    "|   1M.txt   | 1,000,000  | 85M       |\n",
    "|   5M.txt   | 5,000,000  | 428M      |\n",
    "|  25M.txt   | 25,000,000 | 2.1G      |\n",
    "\n",
    "Performance (in second):\n",
    "\n",
    "| Input file | Distance 0 | Distance 1 | Distance 2  |\n",
    "| :--------: | ---------- | ---------- | ----------- |\n",
    "|  100.txt   | 0.000120   | 0.002948   | 0.002877    |\n",
    "|   1K.txt   | 0.000390   | 0.016582   | 0.131046    |\n",
    "|  10K.txt   | 0.003342   | 0.148118   | 1.858770    |\n",
    "|  100K.txt  | 0.040530   | 1.492312   | 21.979624   |\n",
    "|   1M.txt   | 0.545091   | 16.050876  | 287.006949  |\n",
    "|   5M.txt   | 2.829443   | 72.055627  | 1526.300508 |\n",
    "|  25M.txt   | 18.832576  | 250.135241 | 5350.679652 |\n",
    "\n",
    "Result (# of output sentences)\n",
    "\n",
    "| Input file | Distance 0 | Distance 1 | Distance 2 |\n",
    "| :--------: | ---------- | ---------- | ---------- |\n",
    "|  100.txt   | 98         | 98         | 98         |\n",
    "|   1K.txt   | 921        | 921        | 917        |\n",
    "|  10K.txt   | 9179       | 9160       | 9075       |\n",
    "|  100K.txt  | 84111      | 83646      | 80873      |\n",
    "|   1M.txt   | 769170     | 760391     | 714946     |\n",
    "|   5M.txt   | 3049422    | 2996383    | 2763966    |\n",
    "|  25M.txt   | 8703720    | 8506155    | 7712287    |\n",
    "\n",
    "---\n",
    "\n",
    "## Reference\n",
    "\n",
    "The **Big Sentences** problem is described in [Craig's webpage](http://mgnet.org/~douglas/Classes/common-problems/index.html#BigSentences), which also contains all sentence files used in the above section.\n",
    "\n",
    "---\n",
    "\n",
    "## Roadmap\n",
    "\n",
    "- [ ] Add unit test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
